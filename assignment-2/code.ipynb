{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, gensim\n",
    "import os\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you like adult comedy cartoons, like South ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...\n",
       "1  If you like adult comedy cartoons, like South ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = ['comments1k/0_9.txt', 'comments1k/1_7.txt']\n",
    "\n",
    "# create an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# loop through all files in the folder\n",
    "for filename in folder_path:\n",
    "        # read the file\n",
    "        with open(filename, \"r\") as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # append the data to the list\n",
    "        data.append({\"data\": content})\n",
    "\n",
    "# create a DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# display the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saima_x4lzx52\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "df['data'] = df['data'].str.replace('&\\w+;','')\n",
    "df['data'] = df['data'].apply(lambda x: re.sub('<.*?>', '', x))\n",
    "\n",
    "df['data'] = df['data'].str.lower()\n",
    "\n",
    "df['data'] = df['data'].str.replace('[^\\w\\s]',' ')\n",
    "# Load the stop words from NLTK\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['data'] = df['data'].apply(lambda x:' '.join([w for w in x.split() if w not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data    bromwell high cartoon comedy ran time programs...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data    like adult comedy cartoons like south park nea...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pprint(df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bromwell', 'high', 'cartoon', 'comedy', 'ran', 'time', 'programs', 'school', 'life', 'teachers', 'years', 'teaching', 'profession', 'lead', 'believe', 'bromwell', 'high', 'satire', 'much', 'closer', 'reality', 'teachers', 'scramble', 'survive', 'financially', 'insightful', 'students', 'see', 'right', 'pathetic', 'teachers', 'pomp', 'pettiness', 'whole', 'situation', 'remind', 'schools', 'knew', 'students', 'saw', 'episode', 'student', 'repeatedly', 'tried', 'burn', 'school', 'immediately', 'recalled', 'high', 'classic', 'line', 'inspector', 'sack', 'one', 'teachers', 'student', 'welcome', 'bromwell', 'high', 'expect', 'many', 'adults', 'age', 'think', 'bromwell', 'high', 'far', 'fetched', 'pity']]\n",
      "\n",
      "[['like', 'adult', 'comedy', 'cartoons', 'like', 'south', 'park', 'nearly', 'similar', 'format', 'small', 'adventures', 'three', 'teenage', 'girls', 'bromwell', 'high', 'keisha', 'natella', 'latrina', 'given', 'exploding', 'sweets', 'behaved', 'like', 'bitches', 'think', 'keisha', 'good', 'leader', 'also', 'small', 'stories', 'going', 'teachers', 'school', 'idiotic', 'principal', 'mr', 'bip', 'nervous', 'maths', 'teacher', 'many', 'others', 'cast', 'also', 'fantastic', 'lenny', 'henry', 'gina', 'yashere', 'eastenders', 'chrissie', 'watts', 'tracy', 'ann', 'oberman', 'smack', 'pony', 'doon', 'mackichan', 'dead', 'ringers', 'mark', 'perry', 'blunder', 'nina', 'conti', 'know', 'came', 'canada', 'good', 'good']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "data_words_0 = list(sent_to_words(df.iloc[0]))\n",
    "data_words_1 = list(sent_to_words(df.iloc[1]))\n",
    "print(data_words_0[:1])\n",
    "print()\n",
    "print(data_words_1[:1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'gensim' has no attribute 'ldamodel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Create the LDA model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m lda \u001b[39m=\u001b[39m gensim\u001b[39m.\u001b[39;49mldamodel\u001b[39m.\u001b[39mLDA(data_words_0, num_topics\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Get the top 8 words for each topic\u001b[39;00m\n\u001b[0;32m      5\u001b[0m topics \u001b[39m=\u001b[39m lda\u001b[39m.\u001b[39mtop_topics(\u001b[39m8\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'gensim' has no attribute 'ldamodel'"
     ]
    }
   ],
   "source": [
    "# Create the LDA model\n",
    "lda = gensim.ldamodel.LDA(data_words_0, num_topics=10)\n",
    "\n",
    "# Get the top 8 words for each topic\n",
    "topics = lda.top_topics(8)\n",
    "\n",
    "# Print the top 8 words for each topic\n",
    "for topic, words in topics:\n",
    "    print(topic, ': '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lda\n",
      "  Using cached lda-2.0.0.tar.gz (320 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pbr<4,>=0.6\n",
      "  Using cached pbr-3.1.1-py2.py3-none-any.whl (99 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.13.0 in c:\\users\\saima_x4lzx52\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lda) (1.24.2)\n",
      "Installing collected packages: pbr, lda\n",
      "  Running setup.py install for lda: started\n",
      "  Running setup.py install for lda: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: lda is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Running setup.py install for lda did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [61 lines of output]\n",
      "      c:\\Users\\saima_x4lzx52\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py:771: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "        warnings.warn(\n",
      "      c:\\Users\\saima_x4lzx52\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py:771: UserWarning: Usage of dash-separated 'author-email' will not be supported in future versions. Please use the underscore name 'author_email' instead\n",
      "        warnings.warn(\n",
      "      c:\\Users\\saima_x4lzx52\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py:771: UserWarning: Usage of dash-separated 'pre-hook.sdist_pre_hook' will not be supported in future versions. Please use the underscore name 'pre_hook.sdist_pre_hook' instead\n",
      "        warnings.warn(\n",
      "      c:\\Users\\saima_x4lzx52\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py:58: DistDeprecationWarning: Do not call this function\n",
      "        warnings.warn(\"Do not call this function\", DistDeprecationWarning)\n",
      "      c:\\Users\\saima_x4lzx52\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\command\\easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "        warnings.warn(\n",
      "      c:\\Users\\saima_x4lzx52\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "        warnings.warn(\n",
      "      c:\\Users\\saima_x4lzx52\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py:771: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "        warnings.warn(\n",
      "      c:\\Users\\saima_x4lzx52\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py:771: UserWarning: Usage of dash-separated 'author-email' will not be supported in future versions. Please use the underscore name 'author_email' instead\n",
      "        warnings.warn(\n",
      "      c:\\Users\\saima_x4lzx52\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py:771: UserWarning: Usage of dash-separated 'pre-hook.sdist_pre_hook' will not be supported in future versions. Please use the underscore name 'pre_hook.sdist_pre_hook' instead\n",
      "        warnings.warn(\n",
      "      running install\n",
      "      [pbr] Generating AUTHORS\n",
      "      [pbr] AUTHORS complete (0.0s)\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-cpython-311\n",
      "      creating build\\lib.win-amd64-cpython-311\\lda\n",
      "      creating build\\lib.win-amd64-cpython-311\\lda\\tests\n",
      "      copying lda\\tests\\test_datasets.py -> build\\lib.win-amd64-cpython-311\\lda\\tests\n",
      "      copying lda\\tests\\test_lda.py -> build\\lib.win-amd64-cpython-311\\lda\\tests\n",
      "      copying lda\\tests\\test_lda_reuters.py -> build\\lib.win-amd64-cpython-311\\lda\\tests\n",
      "      copying lda\\tests\\test_lda_sparse.py -> build\\lib.win-amd64-cpython-311\\lda\\tests\n",
      "      copying lda\\tests\\test_lda_transform.py -> build\\lib.win-amd64-cpython-311\\lda\\tests\n",
      "      copying lda\\tests\\test_utils.py -> build\\lib.win-amd64-cpython-311\\lda\\tests\n",
      "      copying lda\\tests\\__init__.py -> build\\lib.win-amd64-cpython-311\\lda\\tests\n",
      "      copying lda\\datasets.py -> build\\lib.win-amd64-cpython-311\\lda\n",
      "      copying lda\\lda.py -> build\\lib.win-amd64-cpython-311\\lda\n",
      "      copying lda\\utils.py -> build\\lib.win-amd64-cpython-311\\lda\n",
      "      copying lda\\_setup_hooks.py -> build\\lib.win-amd64-cpython-311\\lda\n",
      "      copying lda\\__init__.py -> build\\lib.win-amd64-cpython-311\\lda\n",
      "      running egg_info\n",
      "      writing lda.egg-info\\PKG-INFO\n",
      "      writing dependency_links to lda.egg-info\\dependency_links.txt\n",
      "      writing requirements to lda.egg-info\\requires.txt\n",
      "      writing top-level names to lda.egg-info\\top_level.txt\n",
      "      [pbr] Reusing existing SOURCES.txt\n",
      "      copying lda\\tests\\reuters.ldac -> build\\lib.win-amd64-cpython-311\\lda\\tests\n",
      "      copying lda\\tests\\reuters.titles -> build\\lib.win-amd64-cpython-311\\lda\\tests\n",
      "      copying lda\\tests\\reuters.tokens -> build\\lib.win-amd64-cpython-311\\lda\\tests\n",
      "      copying lda\\_lda.c -> build\\lib.win-amd64-cpython-311\\lda\n",
      "      copying lda\\_lda.pyx -> build\\lib.win-amd64-cpython-311\\lda\n",
      "      copying lda\\gamma.c -> build\\lib.win-amd64-cpython-311\\lda\n",
      "      copying lda\\gamma.h -> build\\lib.win-amd64-cpython-311\\lda\n",
      "      running build_ext\n",
      "      building 'lda._lda' extension\n",
      "      creating build\\temp.win-amd64-cpython-311\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\lda\n",
      "      \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.34.31933\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -Ic:\\Users\\saima_x4lzx52\\AppData\\Local\\Programs\\Python\\Python311\\include -Ic:\\Users\\saima_x4lzx52\\AppData\\Local\\Programs\\Python\\Python311\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.34.31933\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /Tclda/_lda.c /Fobuild\\temp.win-amd64-cpython-311\\Release\\lda/_lda.obj\n",
      "      _lda.c\n",
      "      lda/_lda.c(196): fatal error C1083: Cannot open include file: 'longintrepr.h': No such file or directory\n",
      "      error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.34.31933\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "× Encountered error while trying to install package.\n",
      "╰─> lda\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m lda\u001b[39m.\u001b[39mLDA(n_topics\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, n_iter\u001b[39m=\u001b[39m\u001b[39m1500\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m model\u001b[39m.\u001b[39mfit(data_words_0) \u001b[39m# model.fit_transform(X) is also available\u001b[39;00m\n\u001b[0;32m      3\u001b[0m topic_word \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtopic_word_ \u001b[39m# model.components_ also works\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda' is not defined"
     ]
    }
   ],
   "source": [
    "model = lda.LDA(n_topics=20, n_iter=1500, random_state=1)\n",
    "model.fit(data_words_0) # model.fit_transform(X) is also available\n",
    "topic_word = model.topic_word_ # model.components_ also works\n",
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ''.join(topic_words)))\n",
    "doc_topic = model.doc_topic_\n",
    "for i in range(10):\n",
    "    print(\"{} (top topic: {})\".format(titles[i], doc_topic[i].argmax()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
