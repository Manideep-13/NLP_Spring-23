{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, gensim\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saima_x4lzx52\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "directory = \"comments1k\"\n",
    "comments = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(directory, filename)) as file:\n",
    "            comments.append(file.read().strip())\n",
    "df1 = pd.DataFrame(comments)\n",
    "\n",
    "df1[0] = df1[0].str.replace('&\\w+;','')\n",
    "df1[0] = df1[0].apply(lambda x: re.sub('<.*?>', '', x))\n",
    "\n",
    "df1[0] = df1[0].str.lower()\n",
    "\n",
    "df1[0] = df1[0].str.replace('[^\\w\\s]',' ')\n",
    "# Load the stop words from NLTK\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#df = df1[0].apply(lambda x:' '.join([w for w in x.split() if w not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n"
     ]
    }
   ],
   "source": [
    "pprint(df1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    bromwell high cartoon comedy ran time programs...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "year integrating kubrick journey its it both\n",
      "Topic #1:\n",
      "year integrating kubrick journey its it both\n",
      "Topic #2:\n",
      "year integrating kubrick journey its it both\n",
      "Topic #3:\n",
      "of the and film his to is\n",
      "Topic #4:\n",
      "year integrating kubrick journey its it both\n",
      "Topic #5:\n",
      "year integrating kubrick journey its it both\n",
      "Topic #6:\n",
      "year integrating kubrick journey its it both\n",
      "Topic #7:\n",
      "year integrating kubrick journey its it both\n",
      "Topic #8:\n",
      "year integrating kubrick journey its it both\n",
      "Topic #9:\n",
      "year integrating kubrick journey its it both\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# Create a count vectorizer to convert text data to a matrix of word counts\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the text data to a matrix of word counts\n",
    "count_matrix = count_vectorizer.fit_transform(df1.iloc[1])\n",
    "\n",
    "# Create an instance of LDA and fit it to the count matrix\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "lda.fit(count_matrix)\n",
    "\n",
    "# Output the top 8 words for each topic\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    print(\" \".join([count_vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-8:-1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LatentDirichletAllocation' object has no attribute 'LDA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#X.sum()\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m lda\u001b[39m.\u001b[39;49mLDA(n_topics\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, n_iter\u001b[39m=\u001b[39m\u001b[39m1500\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m model\u001b[39m.\u001b[39mfit(df[\u001b[39m0\u001b[39m]) \u001b[39m# model.fit_transform(X) is also available\u001b[39;00m\n\u001b[0;32m      5\u001b[0m topic_word \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtopic_word_ \u001b[39m# model.components_ also works\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LatentDirichletAllocation' object has no attribute 'LDA'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#X.sum()\n",
    "model = lda.LDA(n_topics=20, n_iter=1500, random_state=1)\n",
    "model.fit(df[0]) # model.fit_transform(X) is also available\n",
    "topic_word = model.topic_word_ # model.components_ also works\n",
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))\n",
    "doc_topic = model.doc_topic_\n",
    "for i in range(10):\n",
    "    print(\"{} (top topic: {})\".format(titles[i], doc_topic[i].argmax()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lda\n",
      "  Downloading lda-2.0.0.tar.gz (320 kB)\n",
      "     -------------------------------------- 320.9/320.9 kB 2.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pbr<4,>=0.6\n",
      "  Downloading pbr-3.1.1-py2.py3-none-any.whl (99 kB)\n",
      "     ---------------------------------------- 99.7/99.7 kB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.0,>=1.13.0 in c:\\python310\\lib\\site-packages (from lda) (1.23.4)\n",
      "Building wheels for collected packages: lda\n",
      "  Building wheel for lda (setup.py): started\n",
      "  Building wheel for lda (setup.py): finished with status 'done'\n",
      "  Created wheel for lda: filename=lda-2.0.0-cp310-cp310-win_amd64.whl size=338644 sha256=d0493b649930277343c6b8c6a7306caede0dbc513269aed11d017457e9251a2d\n",
      "  Stored in directory: c:\\users\\saima_x4lzx52\\appdata\\local\\pip\\cache\\wheels\\9d\\32\\fa\\07fdf278a0b24269ce4d0be3d642c28dd0e888a4c5f2031279\n",
      "Successfully built lda\n",
      "Installing collected packages: pbr, lda\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'c:\\\\Python310\\\\Scripts\\\\pbr.exe' -> 'c:\\\\Python310\\\\Scripts\\\\pbr.exe.deleteme'\n",
      "\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
